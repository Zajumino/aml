{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from cnn_classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128,128,3)\n",
    "in_channels = 3\n",
    "out_classes = 4\n",
    "filters = [8,8,16,16,32,32,48,64,80]\n",
    "kernel_size = [3,3,3,3,3,3,3,3,3]\n",
    "strides = [1,2,1,2,1,2,1,1,1]\n",
    "padding='valid'\n",
    "activation='relu'\n",
    "downsampling_mode='max'\n",
    "flatten=False\n",
    "fc=[128,16]\n",
    "dropout = 0.5\n",
    "spatial_dropout = 0.2\n",
    "lambda_l2 = 0.0005\n",
    "lrate = 0.001\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "metrics = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn_classifier_network(input_shape, in_channels, out_classes, filters, kernel_size, strides, padding=padding, activation=activation, downsampling_mode=downsampling_mode, flatten=flatten, fc=fc)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((1,128,128,3))\n",
    "y = model(x)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_rotations(dirname, filebase):\n",
    "    '''Read results from dirname from files matching filebase'''\n",
    "    \n",
    "    # The set of files in the directory\n",
    "    files = fnmatch.filter(os.listdir(dirname), filebase)\n",
    "    files.sort()\n",
    "    results = []\n",
    "    \n",
    "    # Loop over matching files\n",
    "    for f in files:\n",
    "        fp = open(\"%s/%s\"%(dirname,f), \"rb\")\n",
    "        r = pickle.load(fp)\n",
    "        fp.close()\n",
    "        results.append(r)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filebase = \"image_Csize_3_3_3_3_3_Cfilters_10_20_30_40_50_Pool_2_2_2_2_2_Pad_valid_hidden_50_20_drop_0.500_L2_0.000500_LR_0.001000_ntrain_*_rot_*_results.pkl\"\n",
    "results = read_all_rotations(\"results\", filebase)\n",
    "filebase = \"image_Csize_3_3_3_3_3_3_3_3_3_Cfilters_8_8_16_16_32_32_48_64_80_Pool_1_2_1_2_1_2_1_1_1_Pad_valid_hidden_128_16_drop_0.500_LR_0.001000_ntrain_*_rot_*_results.pkl\"\n",
    "results_d = read_all_rotations(\"results\", filebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(results)) # should be 20*7 = 140 eventually\n",
    "results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['history'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curve\n",
    "plt.figure()\n",
    "plt.plot(results[0]['history']['val_loss'], label='loss_val 0')\n",
    "plt.plot(results[1]['history']['val_loss'], label='loss_val 1')\n",
    "plt.plot(results[2]['history']['val_loss'], label='loss_val 2')\n",
    "plt.plot(results[3]['history']['val_loss'], label='loss_val 3')\n",
    "plt.plot(results[4]['history']['val_loss'], label='loss_val 4')\n",
    "plt.ylabel('validation loss (sparse categorical cross-entropy)')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curve\n",
    "plt.figure()\n",
    "plt.plot(results[0]['history']['val_sparse_categorical_accuracy'], label='acc_val 0')\n",
    "plt.plot(results[1]['history']['val_sparse_categorical_accuracy'], label='acc_val 1')\n",
    "plt.plot(results[2]['history']['val_sparse_categorical_accuracy'], label='acc_val 2')\n",
    "plt.plot(results[3]['history']['val_sparse_categorical_accuracy'], label='acc_val 3')\n",
    "plt.plot(results[4]['history']['val_sparse_categorical_accuracy'], label='acc_val 4')\n",
    "plt.ylabel('validation accuracy (sparse categorical accuracy)')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_shallow = []\n",
    "test_eval_deep = []\n",
    "for i in range(5):\n",
    "    test_eval_shallow.append(results[i]['predict_testing_eval'][1])\n",
    "    test_eval_deep.append(results_d[i]['predict_testing_eval'][1])\n",
    "test_eval_shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(test_eval_shallow, alpha = 0.5)\n",
    "plt.hist(test_eval_deep, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core50 import *\n",
    "\n",
    "rotation = 0\n",
    "base_dir = '/home/ikang/datasets/core50_128x128'\n",
    "\n",
    "core = Core50('core50_df.pkl')\n",
    "\n",
    "# Set the problem class IDs\n",
    "objects = [4,5,6,8]\n",
    "core.set_problem_class_by_equality('class', objects)\n",
    "\n",
    "# Select only these object classes (remove all others)\n",
    "core.filter_problem_class()\n",
    "\n",
    "# Folds by pairs of condition ((1,2), (3,4), ...)\n",
    "folds = core.create_subsets_by_membership('condition', list(zip(range(1,11,2),range(2,11,2))))\n",
    "\n",
    "_, _, df_testing = core.create_training_validation_testing(rotation, folds, 3)\n",
    "\n",
    "# use with mini dataset\n",
    "df_testing = df_testing[df_testing['fname'].str.contains('0.png')]\n",
    "\n",
    "ds_testing = tf.data.Dataset.from_tensor_slices(df_testing[['fname', 'problem_class']].to_numpy())\n",
    "\n",
    "ds_testing = ds_testing.map(lambda x: tf.py_function(func=Core50.prepare_single_example, inp=[base_dir, x], Tout=(tf.float32, tf.int8)))\n",
    "\n",
    "#ds_testing.map(lambda x: x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in ds_testing.take(1):\n",
    "    plt.imshow(element[0].numpy())\n",
    "    print('true:', element[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ff0b7ab3763eb4695c0fd03857392e84b2afa28f07ed06f6a832d9e70097f46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
